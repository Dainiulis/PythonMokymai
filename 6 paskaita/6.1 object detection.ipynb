{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Įsikeliame reikalingas bibliotekas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Įsikeliame duomenis\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) =  keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizuojame\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "y_valid_one_hot = keras.utils.to_categorical(y_valid, 10)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 30, 30, 10)        280       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 15, 15, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 20)        1820      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 6, 6, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                57680     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 60,590\n",
      "Trainable params: 60,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=10, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(keras.layers.AveragePooling2D())\n",
    "model.add(keras.layers.Conv2D(filters=20, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.AveragePooling2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 11s 16ms/step - loss: 1.6562 - accuracy: 0.3993 - val_loss: 1.4665 - val_accuracy: 0.4700\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 12s 16ms/step - loss: 1.3835 - accuracy: 0.5040 - val_loss: 1.3714 - val_accuracy: 0.5098\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.2944 - accuracy: 0.5416 - val_loss: 1.2746 - val_accuracy: 0.5624\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.2263 - accuracy: 0.5656 - val_loss: 1.2273 - val_accuracy: 0.5732\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1721 - accuracy: 0.5883 - val_loss: 1.1859 - val_accuracy: 0.5830\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.1223 - accuracy: 0.6063 - val_loss: 1.1710 - val_accuracy: 0.5972\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 1.0876 - accuracy: 0.6165 - val_loss: 1.1378 - val_accuracy: 0.6034\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0474 - accuracy: 0.6339 - val_loss: 1.0986 - val_accuracy: 0.6160\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 12s 17ms/step - loss: 1.0126 - accuracy: 0.6452 - val_loss: 1.0778 - val_accuracy: 0.6138\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.9919 - accuracy: 0.6517 - val_loss: 1.0776 - val_accuracy: 0.6232\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.9630 - accuracy: 0.6641 - val_loss: 1.1096 - val_accuracy: 0.6068\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.9414 - accuracy: 0.6714 - val_loss: 1.0476 - val_accuracy: 0.6416\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.9197 - accuracy: 0.6799 - val_loss: 1.0365 - val_accuracy: 0.6442\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.8995 - accuracy: 0.6870 - val_loss: 1.0297 - val_accuracy: 0.6444\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8830 - accuracy: 0.6904 - val_loss: 1.0661 - val_accuracy: 0.6340\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8611 - accuracy: 0.7005 - val_loss: 1.0452 - val_accuracy: 0.6380\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.8444 - accuracy: 0.7051 - val_loss: 1.0395 - val_accuracy: 0.6486\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.8324 - accuracy: 0.7084 - val_loss: 1.0640 - val_accuracy: 0.6380\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8154 - accuracy: 0.7167 - val_loss: 1.0272 - val_accuracy: 0.6506\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7996 - accuracy: 0.7213 - val_loss: 1.0435 - val_accuracy: 0.6442\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7866 - accuracy: 0.7266 - val_loss: 1.0483 - val_accuracy: 0.6488\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7743 - accuracy: 0.7299 - val_loss: 1.0221 - val_accuracy: 0.6522\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7618 - accuracy: 0.7336 - val_loss: 1.0713 - val_accuracy: 0.6394\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7493 - accuracy: 0.7402 - val_loss: 1.0721 - val_accuracy: 0.6360\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7352 - accuracy: 0.7430 - val_loss: 1.0723 - val_accuracy: 0.6412\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7247 - accuracy: 0.7470 - val_loss: 1.0420 - val_accuracy: 0.6574\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7150 - accuracy: 0.7517 - val_loss: 1.0680 - val_accuracy: 0.6468\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6967 - accuracy: 0.7560 - val_loss: 1.0767 - val_accuracy: 0.6482\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6880 - accuracy: 0.7608 - val_loss: 1.0884 - val_accuracy: 0.6492\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6790 - accuracy: 0.7613 - val_loss: 1.0985 - val_accuracy: 0.6440\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6659 - accuracy: 0.7678 - val_loss: 1.0834 - val_accuracy: 0.6504\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.6580 - accuracy: 0.7701 - val_loss: 1.0883 - val_accuracy: 0.6506\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6480 - accuracy: 0.7744 - val_loss: 1.0946 - val_accuracy: 0.6518\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6406 - accuracy: 0.7745 - val_loss: 1.1253 - val_accuracy: 0.6536\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6301 - accuracy: 0.7787 - val_loss: 1.1487 - val_accuracy: 0.6422\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6221 - accuracy: 0.7810 - val_loss: 1.1266 - val_accuracy: 0.6502\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.6109 - accuracy: 0.7864 - val_loss: 1.1499 - val_accuracy: 0.6422\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.6023 - accuracy: 0.7888 - val_loss: 1.1479 - val_accuracy: 0.6480\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.5986 - accuracy: 0.7901 - val_loss: 1.1607 - val_accuracy: 0.6472oss: 0.5993 - accuracy\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.5864 - accuracy: 0.7928 - val_loss: 1.1839 - val_accuracy: 0.6394\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.5764 - accuracy: 0.7963 - val_loss: 1.1622 - val_accuracy: 0.6504\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.5690 - accuracy: 0.8022 - val_loss: 1.2202 - val_accuracy: 0.6412\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.5619 - accuracy: 0.8034 - val_loss: 1.1976 - val_accuracy: 0.6460\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.5528 - accuracy: 0.8068 - val_loss: 1.2535 - val_accuracy: 0.6378\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.5478 - accuracy: 0.8079 - val_loss: 1.2108 - val_accuracy: 0.6402\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.5393 - accuracy: 0.8112 - val_loss: 1.2489 - val_accuracy: 0.6442\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5329 - accuracy: 0.8106 - val_loss: 1.2751 - val_accuracy: 0.6360\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.5248 - accuracy: 0.8144 - val_loss: 1.2377 - val_accuracy: 0.6402\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5198 - accuracy: 0.8165 - val_loss: 1.2753 - val_accuracy: 0.6468\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5110 - accuracy: 0.8193 - val_loss: 1.2891 - val_accuracy: 0.6436\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.5071 - accuracy: 0.8215 - val_loss: 1.2812 - val_accuracy: 0.6412\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.4980 - accuracy: 0.8246 - val_loss: 1.3089 - val_accuracy: 0.6404\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.4910 - accuracy: 0.8257 - val_loss: 1.3260 - val_accuracy: 0.6354\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.4824 - accuracy: 0.8297 - val_loss: 1.3171 - val_accuracy: 0.6376\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.4818 - accuracy: 0.8296 - val_loss: 1.4026 - val_accuracy: 0.6360\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4736 - accuracy: 0.8316 - val_loss: 1.3634 - val_accuracy: 0.6362\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 17s 24ms/step - loss: 0.4638 - accuracy: 0.8365 - val_loss: 1.3593 - val_accuracy: 0.6356\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4619 - accuracy: 0.8368 - val_loss: 1.4148 - val_accuracy: 0.6294\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4581 - accuracy: 0.8379 - val_loss: 1.3871 - val_accuracy: 0.6390\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4454 - accuracy: 0.8425 - val_loss: 1.4534 - val_accuracy: 0.6296\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4429 - accuracy: 0.8423 - val_loss: 1.4533 - val_accuracy: 0.6330\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4382 - accuracy: 0.8453 - val_loss: 1.4342 - val_accuracy: 0.6360\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4313 - accuracy: 0.8460 - val_loss: 1.4461 - val_accuracy: 0.6330\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.4275 - accuracy: 0.8480 - val_loss: 1.4817 - val_accuracy: 0.6288\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.4205 - accuracy: 0.8493 - val_loss: 1.4658 - val_accuracy: 0.6306\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.4170 - accuracy: 0.8515 - val_loss: 1.5197 - val_accuracy: 0.6308\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.4137 - accuracy: 0.8534 - val_loss: 1.5323 - val_accuracy: 0.6302\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.4039 - accuracy: 0.8572 - val_loss: 1.5453 - val_accuracy: 0.6336\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.4023 - accuracy: 0.8564 - val_loss: 1.5583 - val_accuracy: 0.6316\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 19s 26ms/step - loss: 0.3997 - accuracy: 0.8583 - val_loss: 1.5507 - val_accuracy: 0.6280\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.3885 - accuracy: 0.8610 - val_loss: 1.5847 - val_accuracy: 0.6316\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.3898 - accuracy: 0.8615 - val_loss: 1.6229 - val_accuracy: 0.6276\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.3821 - accuracy: 0.8623 - val_loss: 1.6436 - val_accuracy: 0.6290\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.3766 - accuracy: 0.8659 - val_loss: 1.6636 - val_accuracy: 0.6236\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.3720 - accuracy: 0.8680 - val_loss: 1.6542 - val_accuracy: 0.6236\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3667 - accuracy: 0.8688 - val_loss: 1.6666 - val_accuracy: 0.6258\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.3624 - accuracy: 0.8717 - val_loss: 1.7065 - val_accuracy: 0.6240\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.3573 - accuracy: 0.8721 - val_loss: 1.7375 - val_accuracy: 0.6258\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.3560 - accuracy: 0.8734 - val_loss: 1.7535 - val_accuracy: 0.6214\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 0.3494 - accuracy: 0.8737 - val_loss: 1.7460 - val_accuracy: 0.6216\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.3458 - accuracy: 0.8781 - val_loss: 1.8087 - val_accuracy: 0.6190\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.3408 - accuracy: 0.8771 - val_loss: 1.7990 - val_accuracy: 0.6260\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3387 - accuracy: 0.8784 - val_loss: 1.8357 - val_accuracy: 0.6204\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3300 - accuracy: 0.8829 - val_loss: 1.8360 - val_accuracy: 0.6248\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3326 - accuracy: 0.8797 - val_loss: 1.9118 - val_accuracy: 0.6204\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3255 - accuracy: 0.8811 - val_loss: 1.8653 - val_accuracy: 0.6190\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3205 - accuracy: 0.8852 - val_loss: 1.9123 - val_accuracy: 0.6180\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3140 - accuracy: 0.8879 - val_loss: 1.9336 - val_accuracy: 0.6204\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3173 - accuracy: 0.8876 - val_loss: 1.9954 - val_accuracy: 0.6176\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.3138 - accuracy: 0.8867 - val_loss: 1.9598 - val_accuracy: 0.6182\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3051 - accuracy: 0.8906 - val_loss: 2.0042 - val_accuracy: 0.6246\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3042 - accuracy: 0.8911 - val_loss: 2.0418 - val_accuracy: 0.6188\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.3072 - accuracy: 0.8894 - val_loss: 2.0230 - val_accuracy: 0.6166\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2972 - accuracy: 0.8944 - val_loss: 2.0641 - val_accuracy: 0.6234\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.2906 - accuracy: 0.8973 - val_loss: 2.0562 - val_accuracy: 0.6244\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2920 - accuracy: 0.8951 - val_loss: 2.1241 - val_accuracy: 0.6180\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.2882 - accuracy: 0.8975 - val_loss: 2.1411 - val_accuracy: 0.6148\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.2805 - accuracy: 0.9008 - val_loss: 2.1325 - val_accuracy: 0.6166\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.2788 - accuracy: 0.8992 - val_loss: 2.1873 - val_accuracy: 0.6182\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.2746 - accuracy: 0.9015 - val_loss: 2.2303 - val_accuracy: 0.6176\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train_one_hot, validation_data=(X_valid, y_valid_one_hot), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nupiesti confusion matrix\n",
    "# kia architektura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(X_train)\n",
    " \n",
    "#training\n",
    "batch_size = 64\n",
    " \n",
    "opt_rms = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-17fe3edcd21a>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/125\n",
      "703/703 [==============================] - 266s 378ms/step - loss: 1.9684 - accuracy: 0.4040 - val_loss: 1.5255 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 2/125\n",
      "703/703 [==============================] - 287s 409ms/step - loss: 1.3353 - accuracy: 0.5646 - val_loss: 1.1837 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 3/125\n",
      "703/703 [==============================] - 299s 426ms/step - loss: 1.1245 - accuracy: 0.6372 - val_loss: 1.2078 - val_accuracy: 0.6409 - lr: 0.0010\n",
      "Epoch 4/125\n",
      "645/703 [==========================>...] - ETA: 23s - loss: 1.0275 - accuracy: 0.6705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-17fe3edcd21a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit_generator(datagen.flow(X_train, y_train_one_hot, batch_size=batch_size),\\\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     verbose=1,validation_data=(X_test, y_test_one_hot), callbacks=[LearningRateScheduler(lr_schedule)])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1463\u001b[0m     \"\"\"\n\u001b[0;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train_one_hot, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(X_test, y_test_one_hot), callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "# suskaiciuojeme cf matrix\n",
    "cf_matrix = confusion_matrix(y_test_one_hot.argmax(axis=1), predictions.argmax(axis=1))\n",
    "# konvertuojame i dataframe\n",
    "df_cm = pd.DataFrame(cf_matrix, index=range(10), columns=range(10))\n",
    "print(df_cm)\n",
    "# plot'inam\n",
    "plt.figure(figsize = (15,15))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 4, 4, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 5,497,226\n",
      "Trainable params: 5,493,258\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "num_classes = 10\n",
    "s = 2\n",
    "weight_decay = 1e-2\n",
    "act=\"relu\"\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=glorot_normal(), input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "# First Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 5\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 6\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 7\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "# Second Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 8\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 9\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "# Third Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "\n",
    "# Block 10\n",
    "model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 11  \n",
    "model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(Activation(act))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 12  \n",
    "model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(Activation(act))\n",
    "# Fourth Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 13\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(Activation(act))\n",
    "# Fifth Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "# Final Classifier\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_adm = keras.optimizers.Adadelta()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  4/351 [..............................] - ETA: 29:03 - loss: 2.6376 - accuracy: 0.1133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-29fed2cd4a8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit_generator(datagen.flow(X_train, y_train_one_hot, batch_size=batch_size),\n\u001b[0m\u001b[0;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     verbose=1, validation_data=(X_test, y_test_one_hot))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1463\u001b[0m     \"\"\"\n\u001b[0;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 25\n",
    "model.fit_generator(datagen.flow(X_train, y_train_one_hot, batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size, epochs=epochs, \n",
    "                    verbose=1, validation_data=(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
